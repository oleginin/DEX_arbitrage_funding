import sqlite3
import pandas as pd
import time
import os
from datetime import datetime, timedelta
from contextlib import closing

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# âš™ï¸ ĞšĞĞĞ¤Ğ†Ğ“Ğ£Ğ ĞĞ¦Ğ†Ğ¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PAUSE_AFTER_UPDATE = 15
RESET_HISTORY_ON_START = True
STATS_WARMUP_SEC = 60

# ğŸ”¥ Ğ¢Ğ•ĞŸĞ•Ğ  ĞœĞ˜ ĞŸĞ˜Ğ¨Ğ•ĞœĞ Ğ’Ğ¡Ğ• (ĞĞĞ’Ğ†Ğ¢Ğ¬ ĞœĞ†ĞĞ£Ğ¡Ğ˜)
# ĞœĞ¸ Ğ¿Ñ€Ğ¸Ğ±Ñ€Ğ°Ğ»Ğ¸ Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ğ¸ Ñ–Ğ³Ğ½Ğ¾Ñ€ÑƒĞ²Ğ°Ğ½Ğ½Ñ.
# Min/Max Ğ±ÑƒĞ´ÑƒÑ‚ÑŒ Ñ€Ğ°Ñ…ÑƒĞ²Ğ°Ñ‚Ğ¸ÑÑ Ñ‡ĞµÑĞ½Ğ¾ Ğ¿Ğ¾ Ğ²ÑÑ–Ğ¹ Ñ–ÑÑ‚Ğ¾Ñ€Ñ–Ñ—.

# ğŸ›‘ Ğ¤Ğ†Ğ›Ğ¬Ğ¢Ğ Ğ˜ (Ğ’Ğ¸Ğ¼ĞºĞ½ĞµĞ½Ñ–, Ñ‰Ğ¾Ğ± Ğ±Ğ°Ñ‡Ğ¸Ñ‚Ğ¸ Ğ²ÑÑ– Ğ¼Ğ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸)
MIN_OI_USD = 50000
MIN_VOL_USD = 500000

# â° Ğ¡Ğ˜ĞĞ¥Ğ ĞĞĞ†Ğ—ĞĞ¦Ğ†Ğ¯
MAX_DATA_DELAY_SEC = 60
MAX_SYNC_DIFF_SEC = 25

# --- Ğ¨Ğ›Ğ¯Ğ¥Ğ˜ ---
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(SCRIPT_DIR)
DB_FOLDER = os.path.join(PROJECT_ROOT, 'Database')

SOURCE_DBS = [
    {'name': 'Backpack', 'file': 'backpack_database.db'},
    {'name': 'Paradex', 'file': 'paradex_database.db'},
    {'name': 'Variational', 'file': 'variational_database.db'},
    {'name': 'Extended', 'file': 'extended_database.db'},
    {'name': 'Lighter', 'file': 'lighter_database.db'},
]

TARGET_DB_NAME = 'arbitrage_dashboard.db'
TARGET_DB_PATH = os.path.join(DB_FOLDER, TARGET_DB_NAME)

SCRIPT_START_TIME = time.time()


class C:
    CYAN = '\033[96m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    BOLD = '\033[1m'
    END = '\033[0m'


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ› ï¸ Ğ†ĞĞ†Ğ¦Ğ†ĞĞ›Ğ†Ğ—ĞĞ¦Ğ†Ğ¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def init_target_db():
    if not os.path.exists(DB_FOLDER):
        os.makedirs(DB_FOLDER)

    with closing(sqlite3.connect(TARGET_DB_PATH)) as conn:
        conn.execute('PRAGMA journal_mode=WAL;')
        cursor = conn.cursor()

        cursor.execute('''
            CREATE TABLE IF NOT EXISTS live_opportunities (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                token TEXT,
                route TEXT,
                buy_exchange TEXT,
                sell_exchange TEXT,
                buy_price REAL,
                sell_price REAL,
                spread_pct REAL,
                spread_min_24h REAL,
                spread_max_24h REAL,
                spread_min_30d REAL,
                spread_max_30d REAL,
                net_funding_pct REAL,
                funding_freq TEXT,
                oi_long_usd REAL,
                oi_short_usd REAL,
                vol_long_usd REAL,
                vol_short_usd REAL,
                last_updated TIMESTAMP,
                CONSTRAINT unique_path UNIQUE(token, buy_exchange, sell_exchange)
            )
        ''')

        cursor.execute('''
            CREATE TABLE IF NOT EXISTS spread_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                token TEXT,
                route TEXT, 
                spread_pct REAL,
                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')

        cursor.execute('CREATE INDEX IF NOT EXISTS idx_hist_token_route ON spread_history (token, route);')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_hist_time ON spread_history (timestamp);')

        conn.commit()

        if RESET_HISTORY_ON_START:
            try:
                cursor.execute("DELETE FROM spread_history")
                conn.commit()
                cursor.execute("PRAGMA wal_checkpoint(TRUNCATE);")
                print(f"{C.RED}ğŸ§¹ History CLEARED & WAL Truncated.{C.END}")
            except Exception as e:
                print(f"âš ï¸ Clean error: {e}")

    print(f"{C.GREEN}âœ… Target DB Initialized.{C.END}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“¥ Ğ§Ğ˜Ğ¢ĞĞĞĞ¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_data_from_source(db_config):
    db_path = os.path.join(DB_FOLDER, db_config['file'])
    if not os.path.exists(db_path): return None

    try:
        with closing(sqlite3.connect(db_path, timeout=10, isolation_level=None)) as conn:
            conn.execute('PRAGMA journal_mode=WAL;')
            conn.execute('PRAGMA wal_checkpoint(PASSIVE);')

            query = "SELECT * FROM market_data"
            df = pd.read_sql_query(query, conn)

            if df.empty: return None

            df['last_updated'] = pd.to_datetime(df['last_updated'])
            cutoff_time = datetime.now() - timedelta(seconds=MAX_DATA_DELAY_SEC)
            fresh_df = df[df['last_updated'] > cutoff_time].copy()

            if fresh_df.empty: return None

            fresh_df['exchange'] = db_config['name']
            if 'freq_hours' not in fresh_df.columns: fresh_df['freq_hours'] = 1

            return fresh_df
    except Exception:
        return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§  Ğ ĞĞ—Ğ ĞĞ¥Ğ£ĞĞĞš
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_effective_funding(row):
    exch = row['exchange']
    raw_fund = row['funding_pct']
    freq = max(1, row['freq_hours'])
    if exch == 'Variational':
        return (raw_fund * freq), freq
    else:
        return raw_fund, freq


def calculate_live_routes(all_data_df):
    if all_data_df.empty: return pd.DataFrame()
    results = []
    grouped = all_data_df.groupby('token')

    for token, group in grouped:
        if len(group) < 2: continue

        potential_buys = group[group['ask'] > 0]
        potential_sells = group[group['bid'] > 0]

        for _, buy_row in potential_buys.iterrows():
            if buy_row['oi_usd'] < MIN_OI_USD or buy_row['volume_24h'] < MIN_VOL_USD: continue

            for _, sell_row in potential_sells.iterrows():
                if sell_row['oi_usd'] < MIN_OI_USD or sell_row['volume_24h'] < MIN_VOL_USD: continue
                if buy_row['exchange'] == sell_row['exchange']: continue

                time_diff = abs((buy_row['last_updated'] - sell_row['last_updated']).total_seconds())
                if time_diff > MAX_SYNC_DIFF_SEC: continue

                buy_price = buy_row['ask']
                sell_price = sell_row['bid']

                spread = ((sell_price - buy_price) / buy_price) * 100

                fund_long_pct, freq_long = get_effective_funding(buy_row)
                fund_short_pct, freq_short = get_effective_funding(sell_row)

                hourly_long = fund_long_pct / freq_long
                hourly_short = fund_short_pct / freq_short
                max_freq = max(freq_long, freq_short)
                net_funding_scaled = (hourly_short - hourly_long) * max_freq

                freq_str = f"{int(freq_long)}h / {int(freq_short)}h"
                route_name = f"{buy_row['exchange']} â¡ï¸ {sell_row['exchange']}"

                results.append({
                    'token': token,
                    'route': route_name,
                    'buy_exchange': buy_row['exchange'],
                    'sell_exchange': sell_row['exchange'],
                    'buy_price': buy_price,
                    'sell_price': sell_price,
                    'spread': spread,
                    'net_funding': net_funding_scaled,
                    'funding_freq_str': freq_str,
                    'oi_long': buy_row['oi_usd'],
                    'oi_short': sell_row['oi_usd'],
                    'vol_long': buy_row['volume_24h'],
                    'vol_short': sell_row['volume_24h']
                })

    return pd.DataFrame(results)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ’¾ Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ (Ğ‘Ğ•Ğ— Ğ¤Ğ†Ğ›Ğ¬Ğ¢Ğ Ğ†Ğ’)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def update_history_and_get_stats(df_live):
    if df_live.empty: return df_live

    try:
        with closing(sqlite3.connect(TARGET_DB_PATH, timeout=10)) as conn:
            cursor = conn.cursor()
            cursor.execute("BEGIN TRANSACTION")

            history_data = []
            now_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

            for _, row in df_live.iterrows():
                # ğŸ”¥ ĞœĞ˜ Ğ‘Ğ†Ğ›Ğ¬Ğ¨Ğ• ĞĞ• Ğ†Ğ“ĞĞĞ Ğ£Ğ„ĞœĞ ĞĞ†Ğ§ĞĞ“Ğ. ĞŸĞ¸ÑˆĞµĞ¼Ğ¾ Ñ– Ğ¿Ğ»ÑÑĞ¸, Ñ– Ğ¼Ñ–Ğ½ÑƒÑĞ¸.
                history_data.append((row['token'], row['route'], row['spread'], now_str))

            if history_data:
                cursor.executemany(
                    "INSERT INTO spread_history (token, route, spread_pct, timestamp) VALUES (?, ?, ?, ?)",
                    history_data
                )

            cursor.execute("DELETE FROM spread_history WHERE timestamp < datetime('now', '-30 days', '-1 hour')")
            conn.commit()

            elapsed_time = time.time() - SCRIPT_START_TIME

            if elapsed_time < STATS_WARMUP_SEC:
                for col in ['min_24h', 'max_24h', 'min_30d', 'max_30d']:
                    df_live[col] = df_live['spread']
                return df_live

            else:
                # ğŸ”¥ Ğ§Ğ˜Ğ¢ĞĞ„ĞœĞ Ğ’Ğ¡Ğ•. Ğ† Ğ¿Ğ»ÑÑĞ¸, Ñ– Ğ¼Ñ–Ğ½ÑƒÑĞ¸.
                stats_query = """
                SELECT 
                    token, 
                    route,
                    MIN(spread_pct) as db_min_24h,
                    MAX(spread_pct) as db_max_24h,
                    MIN(spread_pct) as db_min_30d,
                    MAX(spread_pct) as db_max_30d
                FROM spread_history
                WHERE timestamp >= datetime('now', '-24 hours')
                GROUP BY token, route
                """
                df_stats = pd.read_sql_query(stats_query, conn)

                if not df_stats.empty:
                    df_final = pd.merge(df_live, df_stats, on=['token', 'route'], how='left')

                    df_final['min_24h'] = df_final['db_min_24h'].fillna(df_final['spread'])
                    df_final['max_24h'] = df_final['db_max_24h'].fillna(df_final['spread'])
                    df_final['min_30d'] = df_final['db_min_30d'].fillna(df_final['spread'])
                    df_final['max_30d'] = df_final['db_max_30d'].fillna(df_final['spread'])

                    # ğŸ”¥ ĞĞĞĞ’Ğ›Ğ•ĞĞĞ¯ LIVE (ĞœĞĞ¢Ğ•ĞœĞĞ¢Ğ˜Ğ§ĞĞ•)
                    # Ğ¢ÑƒÑ‚ Ğ¿Ñ€Ğ°Ñ†ÑÑ” Ğ·Ğ²Ğ¸Ñ‡Ğ°Ğ¹Ğ½Ğ° Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞ°:
                    # - Ğ¯ĞºÑ‰Ğ¾ spread = -5, Ğ° min_24h = -2 -> ĞĞ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒÑÑ Ğ½Ğ° -5 (Ğ±Ğ¾ Ğ²Ğ¾Ğ½Ğ¾ Ğ¼ĞµĞ½ÑˆĞµ).
                    # - Ğ¯ĞºÑ‰Ğ¾ spread = -1, Ğ° max_24h = -3 -> ĞĞ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒÑÑ Ğ½Ğ° -1 (Ğ±Ğ¾ Ğ²Ğ¾Ğ½Ğ¾ Ğ±Ñ–Ğ»ÑŒÑˆĞµ, Ñ‚Ğ¾Ğ±Ñ‚Ğ¾ Ğ±Ğ»Ğ¸Ğ¶Ñ‡Ğµ Ğ´Ğ¾ 0).
                    # - Ğ¯ĞºÑ‰Ğ¾ spread = +1, Ğ° max_24h = -1 -> ĞĞ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒÑÑ Ğ½Ğ° +1 (Ğ±Ğ¾ + Ğ±Ñ–Ğ»ÑŒÑˆĞµ Ğ·Ğ° -).

                    def force_update_min(row, col_min):
                        current = row['spread']
                        history_min = row[col_min]
                        if current < history_min:  # ĞŸÑ€Ğ¾ÑÑ‚Ğ° Ğ¿ĞµÑ€ĞµĞ²Ñ–Ñ€ĞºĞ° "Ñ‰Ğ¾ Ğ¼ĞµĞ½ÑˆĞµ"
                            return current
                        return history_min

                    def force_update_max(row, col_max):
                        current = row['spread']
                        history_max = row[col_max]
                        if current > history_max:  # ĞŸÑ€Ğ¾ÑÑ‚Ğ° Ğ¿ĞµÑ€ĞµĞ²Ñ–Ñ€ĞºĞ° "Ñ‰Ğ¾ Ğ±Ñ–Ğ»ÑŒÑˆĞµ"
                            return current
                        return history_max

                    df_final['min_24h'] = df_final.apply(lambda x: force_update_min(x, 'min_24h'), axis=1)
                    df_final['max_24h'] = df_final.apply(lambda x: force_update_max(x, 'max_24h'), axis=1)
                    df_final['min_30d'] = df_final.apply(lambda x: force_update_min(x, 'min_30d'), axis=1)
                    df_final['max_30d'] = df_final.apply(lambda x: force_update_max(x, 'max_30d'), axis=1)

                    return df_final
                else:
                    for col in ['min_24h', 'max_24h', 'min_30d', 'max_30d']:
                        df_live[col] = df_live['spread']
                    return df_live

    except Exception as e:
        print(f"{C.RED}âŒ Stats Error: {e}{C.END}")
        return df_live


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”„ ĞĞĞĞ’Ğ›Ğ•ĞĞĞ¯ Ğ‘Ğ”
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def update_dashboard_db(df_final):
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    try:
        with closing(sqlite3.connect(TARGET_DB_PATH, timeout=10)) as conn:
            cursor = conn.cursor()
            cursor.execute("BEGIN TRANSACTION")

            if not df_final.empty:
                # ğŸ”¥ ĞĞšĞ Ğ£Ğ“Ğ›Ğ•ĞĞĞ¯ Ğ”Ğ 4 Ğ—ĞĞĞšĞ†Ğ’
                cols_to_round = [
                    'buy_price', 'sell_price', 'spread',
                    'min_24h', 'max_24h', 'min_30d', 'max_30d', 'net_funding'
                ]
                for col in cols_to_round:
                    if col in df_final.columns:
                        df_final[col] = df_final[col].round(4)

                data_to_insert = []
                for _, row in df_final.iterrows():
                    data_to_insert.append((
                        row['token'], row['route'], row['buy_exchange'], row['sell_exchange'],
                        row['buy_price'], row['sell_price'], row['spread'],
                        row['min_24h'], row['max_24h'], row['min_30d'], row['max_30d'],
                        row['net_funding'], row['funding_freq_str'],
                        row['oi_long'], row['oi_short'], row['vol_long'], row['vol_short'],
                        timestamp
                    ))

                sql_upsert = '''
                    INSERT INTO live_opportunities 
                    (token, route, buy_exchange, sell_exchange, buy_price, sell_price, 
                    spread_pct, spread_min_24h, spread_max_24h, spread_min_30d, spread_max_30d,
                    net_funding_pct, funding_freq, 
                    oi_long_usd, oi_short_usd, vol_long_usd, vol_short_usd, last_updated)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)

                    ON CONFLICT(token, buy_exchange, sell_exchange) DO UPDATE SET
                        route = excluded.route,
                        buy_price = excluded.buy_price,
                        sell_price = excluded.sell_price,
                        spread_pct = excluded.spread_pct,
                        spread_min_24h = excluded.spread_min_24h,
                        spread_max_24h = excluded.spread_max_24h,
                        spread_min_30d = excluded.spread_min_30d,
                        spread_max_30d = excluded.spread_max_30d,
                        net_funding_pct = excluded.net_funding_pct,
                        oi_long_usd = excluded.oi_long_usd,
                        oi_short_usd = excluded.oi_short_usd,
                        vol_long_usd = excluded.vol_long_usd,
                        vol_short_usd = excluded.vol_short_usd,
                        last_updated = excluded.last_updated
                '''
                cursor.executemany(sql_upsert, data_to_insert)

            cursor.execute("DELETE FROM live_opportunities WHERE last_updated < datetime('now', '-1 hour')")

            conn.commit()
            cursor.execute("PRAGMA wal_checkpoint(PASSIVE);")

    except Exception as e:
        print(f"{C.RED}âŒ Write Error: {e}{C.END}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸš€ MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    print(f"\n{C.CYAN}ğŸš€ ARBITRAGE AGGREGATOR (FULL RANGE STATS){C.END}")
    print(f"{C.YELLOW}Min/Max now includes NEGATIVE spreads.{C.END}")

    init_target_db()

    while True:
        start_time = time.time()
        dfs = []

        for db_conf in SOURCE_DBS:
            df = get_data_from_source(db_conf)
            if df is not None and not df.empty:
                dfs.append(df)

        if not dfs:
            print(f"\r{C.RED}âš ï¸ Waiting for FRESH data...{C.END}", end="")
            time.sleep(1)
            continue

        full_market_data = pd.concat(dfs, ignore_index=True)

        df_live = calculate_live_routes(full_market_data)
        df_final = update_history_and_get_stats(df_live)

        if not df_final.empty:
            df_final = df_final.sort_values(by='spread', ascending=False)

        update_dashboard_db(df_final)

        duration = time.time() - start_time
        count = len(df_final)
        top_spread = df_final.iloc[0]['spread'] if not df_final.empty else 0.0

        ts = datetime.now().strftime('%H:%M:%S')
        print(f"\r{C.CYAN}[{ts}] Routes: {count}. Top: {top_spread:.2f}%. Took: {duration:.3f}s{C.END}", end="")

        time.sleep(PAUSE_AFTER_UPDATE)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print(f"\n{C.RED}ğŸ›‘ Stopped.{C.END}")